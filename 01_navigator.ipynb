{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp navigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install nbdev\n",
    "!pip install fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/fa_convnav\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "% cd /content/drive/My\\ Drive/fa_convnav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#not deps but we need them to use nbdev and run tests\n",
    "from nbdev import * \n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! pip install fastai2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.vision.all import *\n",
    "from torch import torch\n",
    "\n",
    "pets = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                 get_items=get_image_files, \n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=RegexLabeller(pat = r'/([^/]+)_\\d+.jpg$'),\n",
    "                 item_tfms=Resize(460),\n",
    "                 batch_tfms=[*aug_transforms(size=224, max_rotate=30, min_scale=0.75), Normalize.from_stats(*imagenet_stats)])\n",
    "\n",
    "dls = pets.dataloaders(untar_data(URLs.PETS)/\"images\",  bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 36.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "learn = cnn_learner(\n",
    "    dls, \n",
    "    densenet121, \n",
    "    opt_func=partial(Adam, lr=slice(3e-3), wd=0.01, eps=1e-8), \n",
    "    metrics=error_rate, \n",
    "    config=cnn_config(ps=0.33)).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigator\n",
    "\n",
    "> CNN viewer and navigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fa_convnav.models import models\n",
    "from dataclasses import dataclass\n",
    "from pandas import DataFrame, option_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_row(l, m):\n",
    "  \"Construct a convnav dataframe row from information in fastai `learner.named_modules()`\"\n",
    "\n",
    "  # create genaric row data from `l` (model.named_module() layer) and `m` (model_type)\n",
    "  lyr_name = l[0]\n",
    "  lyr_obj = l[1]\n",
    "  ln_split = str(lyr_name).split('.', 4)\n",
    "  ln_n_splits = len(ln_split)\n",
    "  lyr_str = str(lyr_obj)\n",
    "\n",
    "  tch_cls_str = str(type(lyr_obj))\n",
    "  tch_cls_substr =  tch_cls_str[tch_cls_str.find(\"<class\")+8: tch_cls_str.find(\">\")-1]\n",
    "  tch_cls = tch_cls_substr.split('.')[-1]\n",
    "\n",
    "  div = tch_cls if lyr_name == '0' or lyr_name == '1' else ''\n",
    "  mod = tch_cls if ln_n_splits == 2 else ''\n",
    "  blk = tch_cls if ln_n_splits == 3 and not lyr_name.startswith('1') else ''\n",
    "  lyr = lyr_str[:90]\n",
    "\n",
    "  # customise generic row for peculiarities of specific models\n",
    "  if m == 'vgg' or m == 'alexnet':\n",
    "    if ln_n_splits >2: ln_split[2] = '' \n",
    "    blk = ''\n",
    "\n",
    "  elif m == 'squeezenet':\n",
    "     blk = tch_cls if ln_n_splits == 3 and tch_cls == 'Fire' else '' \n",
    "     if blk == 'Fire': lyr = ''   \n",
    "\n",
    "  elif m == 'resnet':\n",
    "    if blk == 'BasicBlock' or blk == 'Bottleneck': lyr = ''\n",
    "    else:\n",
    "      if ln_n_splits > 4: lyr = f\". {lyr_str[:87]}\" \n",
    "      if ln_n_splits == 4 and ln_split[3] == 'downsample': lyr = tch_cls\n",
    "       \n",
    "  elif m == 'densenet':\n",
    "    lyr_name = lyr_name.replace('denseblock', '').replace('denselayer', '')\n",
    "    ln_split = str(lyr_name).split('.', 4)\n",
    "    mod = tch_cls if (lyr_name.startswith('0') and ln_n_splits == 3) or (lyr_name.startswith('1') and ln_n_splits == 2) else ''\n",
    "    blk = tch_cls if ln_n_splits == 4 and tch_cls == '_DenseLayer' else '' \n",
    "    if mod == '_DenseBlock' or mod == '_Transition' or blk == '_DenseLayer': \n",
    "      lyr = ''\n",
    "    else: \n",
    "      if lyr_name == '0' or lyr_name == '1': div = tch_cls \n",
    "      if lyr_name == '0.0': div = f'. {tch_cls}'\n",
    "      \n",
    "  elif m == 'xresnet':\n",
    "    blk = tch_cls if ln_n_splits == 3 and tch_cls == 'ResBlock' else '' \n",
    "    if mod == 'ConvLayer' or blk == 'ResBlock': \n",
    "      lyr = ''\n",
    "    else:\n",
    "      if ln_n_splits < 4: lyr =  lyr_str[:90]\n",
    "      elif ln_n_splits == 4 and tch_cls == 'Sequential': lyr =  tch_cls\n",
    "      elif ln_n_splits == 4 and tch_cls == 'ReLU': lyr =  lyr_str[:90]\n",
    "      elif ln_n_splits == 5 and tch_cls == 'ConvLayer': lyr =  f'. {tch_cls}'\n",
    "      else: lyr =  f'. . {lyr_str[:82]}'\n",
    "\n",
    "  else:\n",
    "    raise Exception(\"Model type not recognised\")\n",
    "  \n",
    "  return {\n",
    "      'Layer_name': lyr_name, \n",
    "      'Model': tch_cls if lyr_name == '' else '',\n",
    "      'Division': div,\n",
    "      'Module': mod,\n",
    "      'Block': blk, \n",
    "      'Layer_description': lyr,\n",
    "      'Torch_class': tch_cls_substr,\n",
    "      'Output_dimensions': '',\n",
    "      'Parameters': '',\n",
    "      'Trainable': '',\n",
    "      'Currently': '',\n",
    "      'div_id': ln_split[0] if ln_n_splits >0 else '',  \n",
    "      'mod_id': ln_split[1] if ln_n_splits >1 else '',  \n",
    "      'blk_id': ln_split[2] if ln_n_splits >2 else '',\n",
    "      'lyr_id': ln_split[3] if ln_n_splits >3 else '',\n",
    "      'tch_cls': tch_cls,\n",
    "      'out_dim': '',\n",
    "      'current': '',\n",
    "      'lyr_blk': '', \n",
    "      'lyr_mod': '',\n",
    "      'blk_mod': '',\n",
    "      'lyr_obj': lyr_obj\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_model(n): \n",
    "    \"Returns tuple of model type and name (e.g. ('resnet', 'resnet50')) given number modules `n` from `learn.model.named_modules()`\"\n",
    "    for d in models:\n",
    "      match = [(k, m) for k, v in d.items() for m, l in v if l == n]\n",
    "      if match != []: break\n",
    "    if len(match) > 0: return match[0] # (model_type, model_name)\n",
    "    assert True, 'Model not supported. Type supported_models() to get a list of supported models.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class CNDataFrame:\n",
    "  \"Compile information from fastai `learner` and 'layer_info(learner)` into a dataframe\"\n",
    "  learner: any\n",
    "  layer_info: tuple\n",
    "\n",
    "  def sz_tn(t):\n",
    "    \"Adds batch size `bs` to a list if layer dimensions `t`\"\n",
    "    return [self.bs if i==0 else s for i, s in enumerate(t)]\n",
    "\n",
    "  def __post_init__(self):\n",
    "    self.model = self.learner.model                                         # fastai `learner.model` object\n",
    "    self.layers = list(self.learner.model.named_modules())                  # fastai `named_modules` method\n",
    "    self.num_layers = len(self.layers)                    \n",
    "    self.model_type, self.model_name = find_model(self.num_layers)\n",
    "\n",
    "    inp, info = self.layer_info                                   \n",
    "    self.input_sizes = [sz for sz in inp[0].shape]                          # `inp_sz` =  (bs, ch, h, w)\n",
    "    self.bs = self.input_sizes[0]                               \n",
    "\n",
    "    # create base dataframe `df` from a list of formatted rows in `layers`\n",
    "    df = DataFrame([get_row(l, self.model_type) for l in self.layers]) \n",
    "\n",
    "    # remove layer descriptions from container rows\n",
    "    df.at[0, 'Layer_description'] = ''\n",
    "    df.loc[(df['Division'].str.contains('Sequential')) | \\\n",
    "          (df['Module'] == 'Sequential') | \\\n",
    "          (df['Module'] == 'AdaptiveConcatPool2d'), 'Layer_description'] = ''\n",
    "\n",
    "    # add layer info (`o`, `p`, `t`, and `Frozen`/`Unfrozen`) from layer_info to all non-container rows\n",
    "    info_gen = ((_, p, t, self.add_bs(o)) for _, p, t, o in info) # info_gen = generator\n",
    "    for row in df.itertuples(): \n",
    "      idx = row.Index\n",
    "      if row.Layer_description not in ['', '. ConvLayer', 'Sequential']:\n",
    "        _, p, t, o = next(info_gen)\n",
    "        df.at[idx, 'Output_dimensions'] = str(o)\n",
    "        df.at[idx, 'Parameters'] =  p\n",
    "        df.at[idx, 'Trainable'] = t\n",
    "        if 'Conv2d' in row.Torch_class:\n",
    "          df.at[idx, 'Currently'] = 'Unfrozen' if t else 'Frozen'\n",
    "\n",
    "    # backfill container rows with summary layer information and layer/block counts\n",
    "    # 1.set up index stores and counters\n",
    "    m, b  = 0, 0                              \n",
    "    layer_count = [0, 0, 0]                                       # layers in [divs, modules, blocks]\n",
    "    block_count = [0, 0]                                          # blocks in [divs, modules]\n",
    "    frozen_count=[[0,0], [0, 0], [0,0]]                           # [Frozen, Unfrozen] layers in [divs, modules, blocks],  \n",
    "\n",
    "    # 2.iterate over rows, incrementing counters with each new row\n",
    "    for row in df.itertuples():\n",
    "      idx = row.Index\n",
    "      if row.Currently == 'Frozen':\n",
    "        for i in [0,1,2]: frozen_count[i][0] += 1 \n",
    "      if row.Currently == 'Unfrozen':\n",
    "        for i in [0,1,2]: frozen_count[i][1] += 1\n",
    "      if row.Layer_description != '':\n",
    "        for i in [0,1,2]: layer_count[i] += 1 \n",
    "\n",
    "      # backfill 'Module' container rows with layer_info and block and layer counts\n",
    "      if (row.Output_dimensions == '' and row.Module != '') or row.Layer_name == '1':\n",
    "        m = idx if m == 0 else m\n",
    "        df.at[m, 'out_dim'] = df.at[idx-1, 'Output_dimensions']\n",
    "        df.at[m, ['current', 'blk_mod', 'lyr_mod']] = self.get_frozen(frozen_count[1]), block_count[1], layer_count[1] \n",
    "        m = idx\n",
    "        layer_count[1] = block_count[1] = 0\n",
    "        for i in [0, 1]: frozen_count[1][i] = 0\n",
    "\n",
    "      # backfill 'Block' container rows with layer_info and layer counts\n",
    "      if (row.Output_dimensions == '' and row.Block != '') or row.Layer_name == '1':\n",
    "        b = idx if b == 0 else b\n",
    "        df.at[b, 'out_dim'] = df.at[idx-1, 'Output_dimensions'] or df.at[idx-2, 'Output_dimensions']  \n",
    "        df.at[b, ['current', 'lyr_blk']] = self.get_frozen(frozen_count[2]), layer_count[2]\n",
    "        b = idx\n",
    "        layer_count[2] = 0\n",
    "        for i in [0, 1]: block_count[i] += 1\n",
    "        for i in [0, 1]: frozen_count[2][i] = 0\n",
    "      \n",
    "    # 3.backfill division container rows with summary layer_info and block and layer counts\n",
    "    div0_idx = df[df['Layer_name'] == '0'].index.tolist()[0]\n",
    "    div1_idx = df[df['Layer_name'] == '1'].index.tolist()[0] \n",
    "\n",
    "    df.at[div0_idx, 'out_dim'] = df.at[div1_idx-1, 'Output_dimensions'] or df.at[div1_idx-2, 'Output_dimensions']  \n",
    "    df.at[div0_idx, ['current', 'lyr_mod', 'blk_mod']] = self.get_frozen(frozen_count[0]), layer_count[0], block_count[0]\n",
    "\n",
    "    df.at[div1_idx, 'out_dim'] = df.iloc[-1]['Output_dimensions']\n",
    "\n",
    "    self._cndf = df\n",
    "\n",
    "  \n",
    "  def add_bs(self, dims):\n",
    "    \"Adds batch size `bs` to a list if layer dimensions `dims`\"\n",
    "    return [self.bs if i==0 else s for i, s in enumerate(dims)]\n",
    "\n",
    "  @staticmethod\n",
    "  def get_frozen(f):\n",
    "    \"Returns a string interpretation of the number of frozen/unfrozen layers in tuple `f`\"\n",
    "    if f[0] == 0: return 'Unfrozen'\n",
    "    elif f[1] == 0: return 'Frozen'\n",
    "    else: return f'{f[0]}/{(f[0]+f[1])} layers frozen'\n",
    "\n",
    "  @property\n",
    "  def output_dimensions(self):\n",
    "    \"Returns output dimensions of model (bs, classes)\"\n",
    "    return self._cndf.iloc[-1]['Output_dimensions']\n",
    "\n",
    "  @property\n",
    "  def frozen_to(self):\n",
    "    \"Returns parameter group model is curently frozen to\"\n",
    "    return self.learner.opt.frozen_idx + 1\n",
    "\n",
    "  @property\n",
    "  def num_param_groups(self):\n",
    "    \"Returns number of parameter groups\"\n",
    "    return len(self.learner.opt.param_groups)\n",
    "\n",
    "  @property\n",
    "  def model_info(self):\n",
    "    \"Return an info string derived from`learn.model`\"  \n",
    "    res = f\"{self.model_type.capitalize()}: {self.model_name.capitalize()}\\n\"\n",
    "    res += f\"Input shape: {self.input_sizes} (bs, ch, h, w)\\n\"\n",
    "    res += f\"Output features: {self.output_dimensions} (bs, classes)\\n\" \n",
    "    res += f\"Currently frozen to parameter group {self.frozen_to} out of {self.num_param_groups}\" \n",
    "    return res\n",
    "\n",
    "  @staticmethod\n",
    "  def supported_models():\n",
    "    \"Prints list of supported models from 'models' list (imported from models)\"\n",
    "    print('Supported models')\n",
    "    print('================\\n')\n",
    "    for d in models:\n",
    "        [[print(m) for m, l in v] for k, v in d.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CNViewer:\n",
    "  \"Class to view a convnav dataframe\"\n",
    "\n",
    "  def copy_layerinfo(self, df):\n",
    "    \"Copy layer information and block/layer counts over from silent columns to displayed columns\"\n",
    "    df.loc[df['Division'] == '', 'Division'] = df['div_id']\n",
    "    df.loc[df['Module'] == '', 'Module'] = df['mod_id']\n",
    "    df.loc[df['Block'] == '', 'Block'] = df['blk_id']\n",
    "    df.loc[df['Output_dimensions'] == '', 'Output_dimensions'] = df['out_dim']\n",
    "    df.loc[df['Currently'] == '', 'Currently'] = df['current']\n",
    "    return df\n",
    "\n",
    "  def view(self, df=None, verbose=3, tight=True, truncate=0, align_cols='left', return_df=False):\n",
    "    \"Display dataframe `df` with options and styling\"\n",
    "\n",
    "    _df = df if df is not None else self._cndf\n",
    "\n",
    "    assert type(_df) == DataFrame and 'Layer_name' in _df.columns, 'Not a valid convnav dataframe'\n",
    "    assert isinstance(truncate, int) and -10 <= truncate <= 10, f\"Argument 'truncate' must be an integer between -10 (show more cols) and +10 (show fewer cols)\"\n",
    "    assert isinstance(verbose, int) and 1 <= verbose <= 4, f\"Argument verbose must be 1 2 or 3 \"\n",
    "    if not isinstance(tight, bool): tight = True\n",
    "\n",
    "    if len(_df) < 16: tight_layout = False\n",
    "    if verbose != 3: truncate = (10, 4, 0, -10)[verbose-1]\n",
    "\n",
    "    _df.index.name = 'Index'\n",
    "\n",
    "    if len(_df) == 0:\n",
    "      print('No data to display')\n",
    "      return None\n",
    "\n",
    "    with option_context(\"display.max_rows\", 1000): \n",
    "      _df_styled = _df.iloc[:,:-(11+truncate)].style.set_properties(**{'text-align': align_cols})\n",
    "      if tight: \n",
    "        display(_df_styled)\n",
    "      else:\n",
    "        display(_df.iloc[:,:-(11+truncate)]) \n",
    "\n",
    "    if return_df: return(_df)\n",
    "\n",
    "  def copy_view(self, **kwargs):\n",
    "    \"Copy over layer information then display dataframe\"\n",
    "    df = cn._cndf.copy()\n",
    "    df = self.copy_layerinfo(df)\n",
    "    self.view(df=df, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CNSearch:\n",
    "  \"Class to search a convnav dataframe, display the results in a datafarme and return the matching layer objects\"\n",
    "\n",
    "  def find_layer(self, df, searchterm, exact):\n",
    "\n",
    "    if isinstance(searchterm, int):\n",
    "      assert searchterm >= 0 and searchterm <= len(self._cndf), f'Layer ID out of range: min 0, max {len(df)}'\n",
    "      x = df.iloc[searchterm].copy()\n",
    "      x = DataFrame(x).transpose()\n",
    "      return x    \n",
    "      \n",
    "    if isinstance(searchterm, float):\n",
    "      searchterm = str(searchterm)\n",
    "\n",
    "    if isinstance(searchterm, dict):\n",
    "      for col, s in searchterm.items():\n",
    "        assert col in df.columns, f'{col} not a valid column identifier. Valid column names are {df.columns[-1]}'\n",
    "        return df[df[col] == s].copy() if exact else df[df[col].str.contains(s)].copy()\n",
    "      return x\n",
    "\n",
    "    if isinstance(searchterm, str):\n",
    "      searchterm = searchterm.strip(' \\.')\n",
    "      cols = {'Layer_name', 'Torch_class', 'Division', 'Module', 'Block', 'Layer_description'}\n",
    "      if exact: \n",
    "        for col in cols:\n",
    "          x = df[df[col] == searchterm].copy()\n",
    "          if not x.empty: return x\n",
    "      else: \n",
    "        for col in cols:\n",
    "          x = df[df[col].str.contains(searchterm)].copy()\n",
    "          if not x.empty: return x\n",
    "      return x\n",
    "         \n",
    "    assert True, 'Unrecognizable searchterm'\n",
    "        \n",
    "  def search(self, searchterm, exact=True): \n",
    "    \"finds any one, list of or combination of container(s), block(s) or layer(s) in the model_df\"\n",
    "\n",
    "    _df = copy(self._cndf)\n",
    "\n",
    "    if isinstance(searchterm, float):\n",
    "      searchterm = str(searchterm)    \n",
    "      \n",
    "    if isinstance(searchterm, int):\n",
    "      _df = self.find_layer(_df, searchterm, True) \n",
    "      \n",
    "    elif isinstance(searchterm, str):\n",
    "      _df = self.find_layer(_df, searchterm, exact)  \n",
    "      \n",
    "    elif isinstance(searchterm, dict):\n",
    "      _df = DataFrame()  \n",
    "      for col, s in searchterm.items():\n",
    "        new_df = self.find_layer(self._cndf, {col:s}, exact)\n",
    "        _df = pd.concat((_df, new_df), axis=0, ignore_index=False).drop_duplicates('Layer_name')\n",
    "\n",
    "    elif isinstance(searchterm, list):\n",
    "      _df = DataFrame()  \n",
    "      for s in searchterm: \n",
    "        new_df = self.find_layer(self._cndf, s, exact)\n",
    "        _df = pd.concat((_df, new_df), axis=0, ignore_index=False).drop_duplicates('Layer_name')\n",
    "\n",
    "    elif isinstance(searchterm, tuple):\n",
    "      for s in searchterm:\n",
    "        _df = self.find_layer(_df, s, exact)\n",
    "\n",
    "    else: \n",
    "      assert True, 'Unrecognizable searchterm'\n",
    "\n",
    "    if _df is not None and not _df.empty:\n",
    "      print(f'{len(_df)} layers found matching searchterm(s): {searchterm}\\n')\n",
    "      self.view(df=_df)\n",
    "      return _df['lyr_obj'].tolist()\n",
    "    else: \n",
    "      print(f'No matches for searchterm(s): {searchterm}\\n')\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvNav(CNDataFrame, CNSearch, CNViewer):\n",
    "  \"Class to view fastai supported CNNs, search and select module(s) and layer(s) for further investigation\"\n",
    "  def __init__(self, learner, layer_info):\n",
    "    super().__init__(learner, layer_info )\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self._cndf)\n",
    "\n",
    "  def __str__(self) -> str:\n",
    "    return self.model_info\n",
    "\n",
    "  def __call__(self):\n",
    "    self.view()\n",
    "\n",
    "  @property\n",
    "  def head(self):\n",
    "    \"Display model head summary info and layers\"\n",
    "    df = self._cndf.copy()\n",
    "    df = df[df['Layer_name'].str.startswith('1')]\n",
    "\n",
    "    res = f\"{self.model_type.capitalize()}: {self.model_name.capitalize()}\\n\"\n",
    "    res += f\"Input shape: {self._cndf.iloc[1]['out_dim']} (bs, filt, h, w)\\n\"\n",
    "    res += f\"Output features: {self.output_dimensions} (bs, classes)\\n\" \n",
    "    print(res)\n",
    "    self.view(df, truncate=1)\n",
    "\n",
    "  @property\n",
    "  def body(self):\n",
    "    \"Display model body summary info and layers\"\n",
    "    df = self._cndf.copy()\n",
    "    df = df.loc[df['Layer_name'].str.startswith('0')]\n",
    "\n",
    "    res = f\"{self.model_type.capitalize()}: {self.model_name.capitalize()}\\n\"\n",
    "    res += f\"Input shape: {self.input_sizes} (bs, ch, h, w)\\n\"\n",
    "    res += f\"Output dimensions: {df.iloc[-1]['Output_dimensions']} (bs, filt, h, w)\\n\"\n",
    "    res += f\"Currently frozen to parameter group {self.frozen_to} out of {self.num_param_groups}\\n\" \n",
    "    print(res)\n",
    "    self.view(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"ConvNav.head\" class=\"doc_header\"><code>ConvNav.head</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nDisplay model head summary info and layers",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ConvNav.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display summary information and layers of the model head. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def navigator_test(test):\n",
    "  \"Navigator\"\n",
    "  print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigator_test('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
