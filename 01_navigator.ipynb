{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp navigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install nbdev\n",
    "!pip install fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/fa_convnav\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "% cd /content/drive/My\\ Drive/fa_convnav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#not deps but we need them to use nbdev and run tests\n",
    "from nbdev import * \n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install fastai2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       ""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.vision.all import *\n",
    "from torch import torch\n",
    "\n",
    "pets = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                 get_items=get_image_files, \n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=RegexLabeller(pat = r'/([^/]+)_\\d+.jpg$'),\n",
    "                 item_tfms=Resize(460),\n",
    "                 batch_tfms=[*aug_transforms(size=224, max_rotate=30, min_scale=0.75), Normalize.from_stats(*imagenet_stats)])\n",
    "\n",
    "dls = pets.dataloaders(untar_data(URLs.PETS)/\"images\",  bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 86.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "learn = cnn_learner(\n",
    "    dls, \n",
    "    resnet18, \n",
    "    opt_func=partial(Adam, lr=slice(3e-3), wd=0.01, eps=1e-8), \n",
    "    metrics=error_rate, \n",
    "    config=cnn_config(ps=0.33)).to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigator\n",
    "\n",
    "> CNN viewer and navigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import gzip, pickle, re\n",
    "from fa_convnav.models import models\n",
    "from dataclasses import dataclass\n",
    "from pandas import DataFrame, option_context, read_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_vars():\n",
    "  #load test_vars from file if not already downloaded\n",
    "  try:\n",
    "    test_learner\n",
    "  except:\n",
    "    with gzip.open(\"test_learner_resnet18\", \"rb\") as f:\n",
    "      test_learner = pickle.load(f)\n",
    "    with gzip.open(\"test_summary_resnet18\", \"rb\") as f:\n",
    "      test_summary = pickle.load(f)\n",
    "  try:\n",
    "    test_df\n",
    "  except:\n",
    "    with gzip.open(\"test_df_resnet18\", \"rb\") as f:\n",
    "      test_df = pickle.load(f)\n",
    "  return test_learner, test_summary, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_row(l, m):\n",
    "  \"Construct dataframe row from `l` (Learner.named_modules() layer) and `m` (model)\"\n",
    "\n",
    "  # create generic row data from `l` (model.named_module() layer) and `m` (model_type)\n",
    "  lyr_name = l[0]\n",
    "  lyr_obj = l[1]\n",
    "  ln_split = str(lyr_name).split('.', 4)\n",
    "  ln_n_splits = len(ln_split)\n",
    "  lyr_str = str(lyr_obj)\n",
    "\n",
    "  tch_cls_str = str(type(lyr_obj))\n",
    "  tch_cls_substr =  tch_cls_str[tch_cls_str.find(\"<class\")+8: tch_cls_str.find(\">\")-1]\n",
    "  tch_cls = tch_cls_substr.split('.')[-1]\n",
    "\n",
    "  div = tch_cls if lyr_name == '0' or lyr_name == '1' else ''\n",
    "  mod = tch_cls if ln_n_splits == 2 else ''\n",
    "  blk = tch_cls if ln_n_splits == 3 and not lyr_name.startswith('1') else ''\n",
    "  lyr = lyr_str[:90]\n",
    "\n",
    "  # customise generic row for peculiarities of specific models\n",
    "  if m == 'vgg' or m == 'alexnet':\n",
    "    if ln_n_splits >2: ln_split[2] = '' \n",
    "    blk = ''\n",
    "\n",
    "  elif m == 'squeezenet':\n",
    "     blk = tch_cls if ln_n_splits == 3 and tch_cls == 'Fire' else '' \n",
    "     if blk == 'Fire': lyr = ''   \n",
    "\n",
    "  elif m == 'resnet':\n",
    "    if blk == 'BasicBlock' or blk == 'Bottleneck': lyr = ''\n",
    "    else:\n",
    "      if ln_n_splits > 4: lyr = f\". . {lyr_str[:86]}\" \n",
    "      if ln_n_splits == 4 and ln_split[3] == 'downsample': lyr = f'Container{tch_cls}'\n",
    "       \n",
    "  elif m == 'densenet':\n",
    "    lyr_name = lyr_name.replace('denseblock', '').replace('denselayer', '')\n",
    "    ln_split = str(lyr_name).split('.', 4)\n",
    "    mod = tch_cls if (lyr_name.startswith('0') and ln_n_splits == 3) or (lyr_name.startswith('1') and ln_n_splits == 2) else ''\n",
    "    blk = tch_cls if ln_n_splits == 4 and tch_cls == '_DenseLayer' else '' \n",
    "    if mod == '_DenseBlock' or mod == '_Transition' or blk == '_DenseLayer': \n",
    "      lyr = ''\n",
    "    else: \n",
    "      if lyr_name == '0' or lyr_name == '1': div = tch_cls \n",
    "      if lyr_name == '0.0': div = f'. {tch_cls}'\n",
    "      \n",
    "  elif m == 'xresnet':\n",
    "    blk = tch_cls if ln_n_splits == 3 and tch_cls == 'ResBlock' else '' \n",
    "    if mod == 'ConvLayer' or blk == 'ResBlock': \n",
    "      lyr = ''\n",
    "    else:\n",
    "      if ln_n_splits < 4: lyr =  lyr_str[:90]\n",
    "      elif ln_n_splits == 4 and tch_cls == 'Sequential': lyr =  f'Container{tch_cls}'\n",
    "      elif ln_n_splits == 4 and tch_cls == 'ReLU': lyr =  lyr_str[:90]\n",
    "      elif ln_n_splits == 5 and tch_cls == 'ConvLayer': lyr =  f'. . Container{tch_cls}'\n",
    "      else: lyr =  f'. . . . {lyr_str[:32]}'\n",
    "\n",
    "  else:\n",
    "    raise Exception(\"Model type not recognised\")\n",
    "  \n",
    "  return {\n",
    "      'Module_name': lyr_name, \n",
    "      'Model': tch_cls if lyr_name == '' else '',\n",
    "      'Division': div,\n",
    "      'Container_child': mod,\n",
    "      'Container_block': blk, \n",
    "      'Layer_description': lyr,\n",
    "      'Torch_class': tch_cls_substr,\n",
    "      'Output_dimensions': '',\n",
    "      'Parameters': '',\n",
    "      'Trainable': '',\n",
    "      'Currently': '',\n",
    "      'div_id': ln_split[0] if ln_n_splits >0 else '',  \n",
    "      'chd_id': ln_split[1] if ln_n_splits >1 else '',  \n",
    "      'blk_id': ln_split[2] if ln_n_splits >2 else '',\n",
    "      'lyr_id': ln_split[3] if ln_n_splits >3 else '',\n",
    "      'tch_cls': tch_cls,\n",
    "      'out_dim': '',\n",
    "      'current': '',\n",
    "      'lyr_blk': '', \n",
    "      'lyr_chd': '',\n",
    "      'blk_chd': '',\n",
    "      'lyr_obj': lyr_obj\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_model(n): \n",
    "    \"Returns tuple of model type and name (e.g. ('resnet', 'resnet50')) given `n`, the number of named_modules in Learner.model.named_modules()\"\n",
    "    for d in models:\n",
    "      match = [(k, m) for k, v in d.items() for m, l in v if l == n]\n",
    "      if match != []: break\n",
    "    if len(match) > 0: return match[0] # (model_type, model_name)\n",
    "    assert True, 'Model not supported. Use `supported_models()` to get a list of supported models.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(find_model(79), ('resnet', 'resnet18'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_infos(infos):\n",
    "  \"Split the rows of infos (learner.summary()) into separate rows\"\n",
    "  return infos.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp_sz(infos):\n",
    "  \"Slice first row of `infos` to give string representation of model input sizes \"\n",
    "  inp_sz = infos[0]\n",
    "  inp_sz_str = inp_sz[inp_sz.find(\"['\")+2:inp_sz.find(\"']\")] \n",
    "  return inp_sz_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_inp_sz([\"Sequential (Input shape: ['128 x 3 x 224 x 224'])\"]), \"128 x 3 x 224 x 224\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_to_gen(infos):\n",
    "  \"Slice the remaining rows of `infos` to give the layers, `m`, output dimensions `o`, parameters `p` and trainable `t` of each layer and return (m,o,p,t) for all layers in a generator\"\n",
    "  lyr_info = infos[4:-17][::2]\n",
    "  info_list = []\n",
    "  for l in lyr_info:\n",
    "    m, *s, p, t = [y for y in l.split(' ') if y !=\"\"]\n",
    "    info_list.append((m, f\"[{' '.join(s)}]\", p, t))\n",
    "  return (i for i in info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test_summary, _ = get_test_vars()\n",
    "gen = infos_to_gen(test_summary.split('\\n'))\n",
    "test_eq(next(gen), ('Conv2d', '[128 x 64 x 112 x 11]', '9,408', 'False'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class CNDF:\n",
    "  \"Compile information from fastai `Learner.model` and 'layer_info(Learner)` into a dataframe\"\n",
    "  learner: any\n",
    "  learner_summary: str\n",
    "\n",
    "  def __post_init__(self):\n",
    "    assert hasattr(self.learner, 'model'), \"Invalid learner: no 'model' attribute\"\n",
    "    self.model = self.learner.model                                         # fastai `Learner.model` object\n",
    "    self.layers = list(self.learner.model.named_modules())                  # fastai `named_modules` method\n",
    "    self.num_layers = len(self.layers)                    \n",
    "    self.model_type, self.model_name = find_model(self.num_layers)\n",
    "\n",
    "    infos_split = split_infos(self.learner_summary)                         # fastai `Learner.summary()` string\n",
    "    self.inp_sz = get_inp_sz(infos_split)\n",
    "    self.bs = self.inp_sz[0]\n",
    "    info_gen = infos_to_gen(infos_split)\n",
    "               \n",
    "    # create base dataframe `df` from a list of formatted rows in `layers`\n",
    "    df = DataFrame([get_row(l, self.model_type) for l in self.layers]) \n",
    "\n",
    "    # remove layer descriptions from container rows\n",
    "    df.at[0, 'Layer_description'] = ''\n",
    "    df.loc[(df['Division'].str.contains('Sequential')) | \\\n",
    "          (df['Container_child'] == 'Sequential') | \\\n",
    "          (df['Container_child'] == 'AdaptiveConcatPool2d'), 'Layer_description'] = ''\n",
    "\n",
    "    for row in df.itertuples(): \n",
    "      idx = row.Index\n",
    "      if row.Layer_description not in ['', '. . ContainerConvLayer', 'ContainerSequential']:\n",
    "        _, o, p, t = next(info_gen)\n",
    "        df.at[idx, 'Output_dimensions'] = str(o)\n",
    "        df.at[idx, 'Parameters'] =  p\n",
    "        df.at[idx, 'Trainable'] = t\n",
    "        if 'Conv2d' in row.Torch_class:\n",
    "          df.at[idx, 'Currently'] = 'Unfrozen' if t else 'Frozen'\n",
    "\n",
    "    # backfill container rows with summary layer information and layer/block counts\n",
    "    # 1.set up index stores and counters\n",
    "    m, b  = 0, 0                              \n",
    "    layer_count = [0, 0, 0]                                       # layers in [div, child, blocks]\n",
    "    block_count = [0, 0]                                          # blocks in [div, childs]\n",
    "    frozen_count=[[0,0], [0, 0], [0,0]]                           # [Frozen, Unfrozen] layers in [div, child, blocks],  \n",
    "\n",
    "    # 2.iterate over rows, incrementing counters with each new row\n",
    "    for row in df.itertuples():\n",
    "      idx = row.Index\n",
    "      if row.Currently == 'Frozen':\n",
    "        for i in [0,1,2]: frozen_count[i][0] += 1 \n",
    "      if row.Currently == 'Unfrozen':\n",
    "        for i in [0,1,2]: frozen_count[i][1] += 1\n",
    "      if row.Layer_description != '':\n",
    "        for i in [0,1,2]: layer_count[i] += 1 \n",
    "\n",
    "      # backfill 'Module' container rows with layer_info and block and layer counts\n",
    "      if (row.Output_dimensions == '' and row.Container_child != '') or row.Module_name == '1':\n",
    "        m = idx if m == 0 else m\n",
    "        df.at[m, 'out_dim'] = df.at[idx-1, 'Output_dimensions']\n",
    "        df.at[m, ['current', 'blk_chd', 'lyr_chd']] = self.get_frozen(frozen_count[1]), block_count[1], layer_count[1] \n",
    "        m = idx\n",
    "        layer_count[1] = block_count[1] = 0\n",
    "        for i in [0, 1]: frozen_count[1][i] = 0\n",
    "\n",
    "      # backfill 'Block' container rows with layer_info and layer counts\n",
    "      if (row.Output_dimensions == '' and row.Container_block != '') or row.Module_name == '1':\n",
    "        b = idx if b == 0 else b\n",
    "        df.at[b, 'out_dim'] = df.at[idx-1, 'Output_dimensions'] or df.at[idx-2, 'Output_dimensions']  \n",
    "        df.at[b, ['current', 'lyr_blk']] = self.get_frozen(frozen_count[2]), layer_count[2]\n",
    "        b = idx\n",
    "        layer_count[2] = 0\n",
    "        for i in [0, 1]: block_count[i] += 1\n",
    "        for i in [0, 1]: frozen_count[2][i] = 0\n",
    "      \n",
    "    # 3.backfill division container rows with summary layer_info and block and layer counts\n",
    "    div0_idx = df[df['Module_name'] == '0'].index.tolist()[0]\n",
    "    div1_idx = df[df['Module_name'] == '1'].index.tolist()[0] \n",
    "\n",
    "    df.at[div0_idx, 'out_dim'] = df.at[div1_idx-1, 'Output_dimensions'] or df.at[div1_idx-2, 'Output_dimensions']  \n",
    "    df.at[div0_idx, ['current', 'lyr_chd', 'blk_chd']] = self.get_frozen(frozen_count[0]), layer_count[0], block_count[0]\n",
    "\n",
    "    df.at[div1_idx, 'out_dim'] = df.iloc[-1]['Output_dimensions']\n",
    "\n",
    "    self._cndf = df\n",
    "\n",
    "  \n",
    "  def add_bs(self, dims):\n",
    "    \"Adds batch size `bs` to a list if layer dimensions `dims`\"\n",
    "    return [self.bs if i==0 else s for i, s in enumerate(dims)]\n",
    "\n",
    "  @staticmethod\n",
    "  def get_frozen(f):\n",
    "    \"Returns a string interpretation of the number of frozen/unfrozen layers in tuple `f`\"\n",
    "    if f[0] == 0: return 'Unfrozen'\n",
    "    elif f[1] == 0: return 'Frozen'\n",
    "    else: return f'{f[0]}/{(f[0]+f[1])} layers frozen'\n",
    "\n",
    "  @property\n",
    "  def output_dimensions(self):\n",
    "    \"Returns output dimensions of model (bs, classes)\"\n",
    "    return self._cndf.iloc[-1]['Output_dimensions']\n",
    "\n",
    "  @property\n",
    "  def frozen_to(self):\n",
    "    \"Returns parameter group model is curently frozen to\"\n",
    "    return self.learner.opt.frozen_idx + 1\n",
    "\n",
    "  @property\n",
    "  def num_param_groups(self):\n",
    "    \"Returns number of parameter groups\"\n",
    "    return len(self.learner.opt.param_groups)\n",
    "\n",
    "  @property\n",
    "  def batch_size(self):\n",
    "    \"Returns the batch size of the current learner\"\n",
    "    return self.bs\n",
    "\n",
    "  @property\n",
    "  def input_sizes(self):\n",
    "    \"Returns the sizes (dimensions bs, ch, h, w) of the model)\"\n",
    "    return self.inp_sz\n",
    "\n",
    "  @property\n",
    "  def model_info(self):\n",
    "    \"Return an info string derived from`Learner.model`\"  \n",
    "    res = f\"{self.model_type.capitalize()}: {self.model_name.capitalize()}\\n\"\n",
    "    res += f\"Input shape: {self.inp_sz} (bs, ch, h, w)\\n\"\n",
    "    res += f\"Output features: {self.output_dimensions} (bs, classes)\\n\" \n",
    "    res += f\"Currently frozen to parameter group {self.frozen_to} out of {self.num_param_groups}\" \n",
    "    return res\n",
    "\n",
    "  @property\n",
    "  def cndf(self):\n",
    "    \"Returns a ConvNav dataframe\"\n",
    "    return self._cndf.copy()\n",
    "\n",
    "  @staticmethod\n",
    "  def supported_models():\n",
    "    \"Prints list of supported models from 'models' list (imported from models)\"\n",
    "    print('Supported models')\n",
    "    print('================\\n')\n",
    "    for d in models:\n",
    "        [[print(m) for m, l in v] for k, v in d.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNDF class builds a dataframe using a fastai Learner and the output of Learner.summary() method. The resulting dataframe, called a CNDF dataframe, combines information from both sources and represents both the structure and information of Learner.model. \n",
    "\n",
    "CNDF is a parent class of ConvNav and a CNDF dataframe is automatically built when a new ConvNav object is instantiated and for most use cases CNDF dataframes should be built this way. However, if there is a need to build a CNDF dataframe in isolation use: \n",
    "\n",
    "```\n",
    "cndf = CNDF(Learner, Learner.summary())\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDF.supported_models\" class=\"doc_header\"><code>CNDF.supported_models</code><a href=\"__main__.py#L134\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>CNDF.supported_models</code>()\n\nPrints list of supported models from 'models' list (imported from models)",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDF.supported_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDF.cndf\" class=\"doc_header\"><code>CNDF.cndf</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturns a ConvNav dataframe",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDF.cndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDF.batch_size\" class=\"doc_header\"><code>CNDF.batch_size</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturns the batch size of the current learner",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDF.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDF.input_sizes\" class=\"doc_header\"><code>CNDF.input_sizes</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturns the sizes (dimensions bs, ch, h, w) of the model)",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDF.input_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDF.output_dimensions\" class=\"doc_header\"><code>CNDF.output_dimensions</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturns output dimensions of model (bs, classes)",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDF.output_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDF.model_info\" class=\"doc_header\"><code>CNDF.model_info</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nReturn an info string derived from`Learner.model`",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDF.model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "#first load test_learner and test_summary() and create CNDF instance `cndf_test`\n",
    "test_learner, test_summary, _ = get_test_vars()\n",
    "cndf_test = CNDF(test_learner, test_summary)\n",
    "\n",
    "test_eq(type(cndf_test._cndf), DataFrame)     # is a dataframe\n",
    "test_eq(len(cndf_test._cndf), 79)             # rows\n",
    "test_eq(len(cndf_test._cndf.columns), 22)     # columns\n",
    "del(cndf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CNDFView:\n",
    "  \"Class to view a CNDF dataframe\"\n",
    "\n",
    "  def copy_layerinfo(self, df):\n",
    "    \"Copy layer information and block/layer counts across from hidden columns to displayed columns\"\n",
    "    df.loc[df['Division'] == '', 'Division'] = df['div_id']\n",
    "    df.loc[df['Container_child'] == '', 'Container_child'] = df['chd_id']\n",
    "    df.loc[df['Container_block'] == '', 'Container_block'] = df['blk_id']\n",
    "    df.loc[df['Output_dimensions'] == '', 'Output_dimensions'] = df['out_dim']\n",
    "    df.loc[df['Currently'] == '', 'Currently'] = df['current']\n",
    "    return df\n",
    "\n",
    "  def check_view_args(self, df, truncate, verbose):\n",
    "    \"Check arguments given to view function, `df`, `truncate` and `verbose` are valid\"\n",
    "    assert type(df) == DataFrame and 'Module_name' in df.columns, \"Not a valid convnav dataframe\"\n",
    "    assert isinstance(truncate, int) and -10 <= truncate <= 10, f\"Argument 'truncate' must be an integer between -10 (show more cols) and +10 (show fewer cols)\"\n",
    "    assert isinstance(verbose, int) and 1 <= verbose <= 5, f\"Argument verbose must be 1 2 or 3 \"\n",
    "\n",
    "  def view(self, df=None, verbose=3, tight=True, truncate=0, align_cols='left', top=False, show=True, return_df=False):\n",
    "    \"Display dataframe `df` with options and styling\"\n",
    "\n",
    "    if not show: return None\n",
    "    _df = df if df is not None else self._cndf.copy()\n",
    "    self.check_view_args(_df, truncate, verbose)\n",
    "    \n",
    "    if not isinstance(tight, bool): tight = True\n",
    "    if len(_df) < 10: tight = False\n",
    "    if verbose != 3: truncate = (10, 4, 0, 0, -10)[verbose-1]\n",
    "    if verbose == 4: _df = self.copy_layerinfo(_df)\n",
    "\n",
    "    post_msg = ''\n",
    "    if top and len(_df) > 10:\n",
    "      post_msg = f'...{len(_df)-10} more layers'\n",
    "      _df = _df.iloc[:10]\n",
    "      tight=False\n",
    "      \n",
    "    if len(_df) == 0:\n",
    "      print('No data to display')\n",
    "      return None\n",
    "\n",
    "    with option_context(\"display.max_rows\", 1000):\n",
    "      _df.index.name = 'Index' \n",
    "      _df_styled = _df.iloc[:,:-(11+truncate)].style.set_properties(**{'text-align': align_cols})\n",
    "      if tight: \n",
    "        display(_df_styled)\n",
    "      else:\n",
    "        display(_df.iloc[:,:-(11+truncate)]) \n",
    "    print(post_msg)\n",
    "    if return_df and df is not None: return(_df)\n",
    "\n",
    "  def copy_view(self, df, **kwargs):\n",
    "    \"Copy over layer information then call `view` to display dataframe\"\n",
    "    df = self.copy_layerinfo(df)\n",
    "    self.view(df=df, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDFView.view\" class=\"doc_header\"><code>CNDFView.view</code><a href=\"__main__.py#L19\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>CNDFView.view</code>(**`df`**=*`None`*, **`verbose`**=*`3`*, **`tight`**=*`True`*, **`truncate`**=*`0`*, **`align_cols`**=*`'left'`*, **`top`**=*`False`*, **`show`**=*`True`*, **`return_df`**=*`False`*)\n\nDisplay dataframe `df` with options and styling",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDFView.view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to format and display a CNDF dataframe. Defaults to displaying the instance dataframe built by CNDF but will accept a valid CNDF dataframe `df` as an argument. Other arguments:\n",
    "\n",
    "\n",
    "*   `verbose`: 1 = Index and Layer_name columns only; 2 = Model structure; 3 = Model Structure and layer_info (output dims, params and frozen/unfrozen) (default);  4 = fill in container columns with layer_info; 5 = expose hidden columns.\n",
    "*   `tight`: False = normal row spacing; True = tight layout with minimal space between rows (best for large models with many rows to display). The default is True but dataframes with fewer than 10 rows are automatically displayed with normal spacing.\n",
    "*   `truncate`: truncate number displayed columns by integer value between -10 and 10. 0 = default. Negative values reveal hidden columns. Overidden when the verbose argument is set to a non-default setting.\n",
    "*   `align_cols`: 'left' (default); 'right' alignment of column data\n",
    "*   `top`: display first 10 rows only followed by a count of undisplayed rows\n",
    "*   `show`: True (default)/False show/hide cell output.\n",
    "*   `return_df`: return the formatted df to the caller if True. False returns None (default). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CNDFSearch:\n",
    "  \"Class to search a CNDF dataframe, display the results in a dataframe and returns matching module object(s)\"\n",
    "\n",
    "  def _find_layer(self, df, searchterm, exact):\n",
    "    \"Searches `df` for `searchterm`, returning exact matches only if `exact=True` otherwise any match\"\n",
    "\n",
    "    if isinstance(searchterm, int):\n",
    "      assert searchterm >= 0 and searchterm <= len(df), f'Layer ID out of range: min 0, max {len(df)}'\n",
    "      #select 'df' row using index from 'searchterm'\n",
    "      x = df.iloc[searchterm].copy()\n",
    "      x = DataFrame(x).transpose()\n",
    "      return x    \n",
    "      \n",
    "    #if searchterm is a float assume it is a layer name (i.e. format 0.0.1) and convert to string\n",
    "    if isinstance(searchterm, float): searchterm = str(searchterm)\n",
    "      \n",
    "    if isinstance(searchterm, dict):\n",
    "      #select rows matching the conditional df[key] ==/contains value (exact=True/false) for dict\n",
    "      for col, s in searchterm.items():\n",
    "        assert col in df.columns, f'{col} not a valid column identifier. Valid column names are {df.columns}'\n",
    "        return df[df[col] == s].copy() if exact else df[df[col].str.contains(s)].copy()\n",
    "      return x\n",
    "\n",
    "    if isinstance(searchterm, str):\n",
    "      #select rows in df where df[col] ==/contains searchterm string (exact=True/False) \n",
    "      #returns results after first matches are found in a column (remining columns not searched)\n",
    "      searchterm = searchterm.strip(' \\.')\n",
    "      cols = {'Module_name', 'Torch_class', 'Division', 'Container_child', 'Container_block', 'Layer_description'}\n",
    "      if exact: \n",
    "        for col in cols:\n",
    "          x = df[df[col] == searchterm].copy()\n",
    "          if not x.empty: return x\n",
    "      else: \n",
    "        for col in cols:\n",
    "          x = df[df[col].str.contains(searchterm)].copy()\n",
    "          if not x.empty: return x\n",
    "      return x\n",
    "         \n",
    "    assert True, 'Unrecognizable searchterm'\n",
    "        \n",
    "  def search(self, searchterm, df=None, exact=True, show=True): \n",
    "    \"Finds any single or combination of container(s), block(s) or layer(s) in the `self._cndf` or `df`\"\n",
    "    if df is not None: \n",
    "      _df = df.copy()\n",
    "    else:\n",
    "       _df = df = self._cndf.copy()\n",
    "\n",
    "    if isinstance(searchterm, float): searchterm = str(searchterm)\n",
    "\n",
    "    if isinstance(searchterm, int): \n",
    "      _df = self._find_layer(_df, searchterm, True) \n",
    "\n",
    "    elif isinstance(searchterm, str): \n",
    "      _df = self._find_layer(_df, searchterm, exact)  \n",
    "\n",
    "    elif isinstance(searchterm, dict):\n",
    "      #concatenate successive search results (logical 'OR') for series of dicts\n",
    "      _df = DataFrame()  \n",
    "      for col, s in searchterm.items():\n",
    "        new_df = self._find_layer(df, {col:s}, exact)\n",
    "        _df = pd.concat((_df, new_df), axis=0, ignore_index=False).drop_duplicates('Module_name')\n",
    "\n",
    "    elif isinstance(searchterm, list):\n",
    "      #concatenate successive search results (logical 'OR') in list\n",
    "      _df = DataFrame()  \n",
    "      for s in searchterm: \n",
    "        new_df = self._find_layer(df, s, exact)\n",
    "        _df = pd.concat((_df, new_df), axis=0, ignore_index=False).drop_duplicates('Module_name')\n",
    "\n",
    "    elif isinstance(searchterm, tuple):\n",
    "      #recursively call find_layer on _df to logical 'AND' successive search results in tuple\n",
    "      for s in searchterm:\n",
    "        _df = self._find_layer(_df, s, exact)\n",
    "\n",
    "    else: assert True, 'Unrecognizable searchterm'\n",
    "\n",
    "    #show matches and return corresponding modules\n",
    "    if _df is not None and not _df.empty:\n",
    "      if show:\n",
    "        print(f'{len(_df)} layers found matching searchterm(s): {searchterm}\\n')\n",
    "        self.view(df=_df)\n",
    "      return _df['lyr_obj'].tolist()\n",
    "    else: \n",
    "      if show: print(f'No matches for searchterm(s): {searchterm}\\n')\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"CNDFSearch.search\" class=\"doc_header\"><code>CNDFSearch.search</code><a href=\"__main__.py#L41\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>CNDFSearch.search</code>(**`searchterm`**, **`df`**=*`None`*, **`exact`**=*`True`*, **`show`**=*`True`*)\n\nFinds any single or combination of container(s), block(s) or layer(s) in the `self._cndf` or `df`",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(CNDFSearch.search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Searchterm` can be:\n",
    "\n",
    "*   `int` : the module with Index number `int` is returned\n",
    "*   `float`: module(s) where `str(float)` matches the Layer_name are returned\n",
    "*   `str`: module(s) with `str` in one of 'Layer_name', 'Torch_class', 'Division', 'Module', 'Block', 'Layer_description' are returned. Columns are searched in this order with the search ending with the first column to make a match/matches. \n",
    "*   `dict`, e.g. {'col', 'str'} matches `str` in column `col` \n",
    "\n",
    "Searchterms can also be a combined as follows:\n",
    "\n",
    "*   `[101, 102, 105]` logical OR of rows matching indexes `101`, `102` plus `103`\n",
    "*   `('0.5', 'conv2d')` logical AND of rows matching `0.5` in Layer_name and `conv2d` in `Layer_description`\n",
    "*   `{{'col1', 'str1'}, {'col2', 'str2'}}` logical OR of matches `str1` in `col1` plus `str2` in `col`'.\n",
    "\n",
    "Return only exact matches between the searchterm and column entry with exact=True (default)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "#first load test df built from resnet18 model and create CNDFSearch instance `cndf_test\n",
    "_, _, test_df = get_test_vars()\n",
    "test_df['lyr_obj'] = None\n",
    "cndf_test = CNDFSearch()\n",
    "\n",
    "test_eq(len(cndf_test.search(12, df=test_df, show=False)), 1)\n",
    "test_eq(len(cndf_test.search('0.6.1.conv2', df=test_df, show=False)), 1)\n",
    "test_eq(len(cndf_test.search(0.6, df=test_df, exact=False, show=False)), 16)\n",
    "test_eq(len(cndf_test.search({'Module_name': '0.6', 'Layer_description':'Conv2d'}, df=test_df, exact=True, show=False)), 1)\n",
    "test_eq(len(cndf_test.search(['0.6', '0.5'], df=test_df, exact=False, show=False)), 32)\n",
    "test_eq(cndf_test.search(('0.6', '0.5'), df=test_df, exact=False, show=False), None)\n",
    "del(cndf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvNav(CNDF, CNDFSearch, CNDFView):\n",
    "  \"Class to view fastai supported CNNs, search and select module(s) and layer(s) for further investigation\"\n",
    "  def __init__(self, learner, learner_summary):\n",
    "    super().__init__(learner, learner_summary)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self._cndf)\n",
    "\n",
    "  def __str__(self) -> str:\n",
    "    return self.model_info\n",
    "\n",
    "  def __call__(self):\n",
    "    self.view(head=True)\n",
    "\n",
    "  def __contains__(self, s):\n",
    "    return self.search(s)\n",
    "\n",
    "  @property\n",
    "  def head(self):\n",
    "    \"Print `model` head summary info and modules\"\n",
    "    df = self._cndf.copy()\n",
    "    df = df[df['Module_name'].str.startswith('1')]\n",
    "    if not df.empty:\n",
    "      res = f\"{self.model_type.capitalize()}: {self.model_name.capitalize()}\\n\"\n",
    "      res += f\"Input shape: {self._cndf.iloc[1]['out_dim']} (bs, filt, h, w)\\n\"\n",
    "      res += f\"Output features: {self.output_dimensions} (bs, classes)\\n\" \n",
    "      print(res)\n",
    "      self.view(df, truncate=1)\n",
    "    else:\n",
    "      res = \"Model has no head\"\n",
    "      print(res)\n",
    "\n",
    "  @property\n",
    "  def body(self):\n",
    "    \"Print `model` body summary info and modules\"\n",
    "    df = self._cndf.copy()\n",
    "    df = df.loc[df['Module_name'].str.startswith('0')]\n",
    "    if not df.empty:\n",
    "      res = f\"{self.model_type.capitalize()}: {self.model_name.capitalize()}\\n\"\n",
    "      res += f\"Input shape: {self.input_sizes} (bs, ch, h, w)\\n\"\n",
    "      res += f\"Output dimensions: {df.iloc[-1]['Output_dimensions']} (bs, filt, h, w)\\n\"\n",
    "      res += f\"Currently frozen to parameter group {self.frozen_to} out of {self.num_param_groups}\\n\" \n",
    "      print(res)\n",
    "      self.view(df)\n",
    "    else:\n",
    "      res = \"Model body has no contents\"\n",
    "      print(res)\n",
    "\n",
    "  @property\n",
    "  def divs(self):\n",
    "    \"Print Summary information from `model` head and body\"\n",
    "    df = self._cndf[(self._cndf['Module_name'] == '0') | (self._cndf['Module_name'] == '1')].copy()\n",
    "\n",
    "    for i in range(2):\n",
    "      df_div = self._cndf.loc[self._cndf['div_id'] == str(i)].copy()\n",
    "      df.iloc[i]['Model'] = self.model_name\n",
    "      df.iloc[i]['Container_child'] = len(df_div[df_div['Container_child'] != ''])\n",
    "      df.iloc[i]['Container_block'] = len(df_div[df_div['Container_block'] != ''])\n",
    "      df.iloc[i]['Layer_description'] = len(df_div[df_div['Layer_description'] != ''])\n",
    "      params = df_div['Parameters'].values\n",
    "      params_summed = sum(filter(lambda i: isinstance(i, int), params))\n",
    "      df.iloc[i]['Parameters'] = params_summed\n",
    "\n",
    "    df['Output_dimensions'] = df['out_dim']\n",
    "    df.iloc[0]['Currently'] = df.iloc[0]['current']\n",
    "\n",
    "    df = df.rename(columns={'Container_child': 'Child modules', 'Container_block': 'Blocks', 'Layer_description': 'Layers'})\n",
    "    print(f\"{self.model_name.capitalize()}\\nDivisions:  body (0), head (1)\\n\")\n",
    "    self.view(df, tight=False)\n",
    "\n",
    "  @property\n",
    "  def dim_transitions(self):\n",
    "    \"Finds layers with different input and output dimensions. These are useful points to apply hooks and callbacks for investigating model activity.\"\n",
    "    df = self._cndf[self._cndf['Torch_class'].str.contains('Conv2d')].copy()\n",
    "\n",
    "    n = []\n",
    "    old_dims = 0\n",
    "    for i, row in enumerate(df.iterrows()):\n",
    "      row=row[1]\n",
    "      new_dims = row['Output_dimensions'].rstrip(']').split(',')[-1]\n",
    "      if new_dims != old_dims:\n",
    "        n.append(i)\n",
    "        old_dims = new_dims\n",
    "    df = df.iloc[n]\n",
    "\n",
    "    print(f\"{self.model_name.capitalize()}\\nLayer dimension changes\\n\")\n",
    "    self.copy_view(df, tight=False)\n",
    "    return df['lyr_obj'].tolist()\n",
    "\n",
    "  @property\n",
    "  def linear_layers(self):\n",
    "    \"Prints and returns all linear layers in the `model`\"\n",
    "    df = self._cndf[self._cndf['Torch_class'].str.contains('Linear')].copy()\n",
    "    df['Division'] = df['div_id']\n",
    "\n",
    "    print(f\"{self.model_name.capitalize()} linear layers\\n\")\n",
    "    self.view(df, truncate=1, tight=False)\n",
    "    return df['lyr_obj'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ConvNav instance, which automatically builds a CNDF dataframe.\n",
    "```\n",
    "cn = ConvNav(Learner, Learner.summary()\n",
    "```\n",
    "View and search the CNDF dataframe to select modules and layers of interest.\n",
    "```\n",
    "cn.view()\n",
    "cn.search('conv2d')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"ConvNav.head\" class=\"doc_header\"><code>ConvNav.head</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nPrint `model` head summary info and modules",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ConvNav.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"ConvNav.body\" class=\"doc_header\"><code>ConvNav.body</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nPrint `model` body summary info and modules",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ConvNav.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"ConvNav.divs\" class=\"doc_header\"><code>ConvNav.divs</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nPrint Summary information from `model` head and body",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ConvNav.divs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"ConvNav.dim_transitions\" class=\"doc_header\"><code>ConvNav.dim_transitions</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nFinds layers with different input and output dimensions. These are useful points to apply hooks and callbacks for investigating model activity.",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ConvNav.dim_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"ConvNav.linear_layers\" class=\"doc_header\"><code>ConvNav.linear_layers</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\nPrints and returns all linear layers in the `model`",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ConvNav.linear_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "#load test_learner and create test object `cn_test`\n",
    "test_learner, test_summary, _ = get_test_vars()\n",
    "cn_test = ConvNav(test_learner, test_summary)\n",
    "\n",
    "test_eq(type(cn_test._cndf), DataFrame)     # is a dataframe\n",
    "test_eq(len(cn_test._cndf), 79)             # rows\n",
    "test_eq(len(cn_test._cndf.columns), 22)     # columns\n",
    "del(cn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Saving and reloading CNDF dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_cndf(cn, filename, path='', with_modules=False):\n",
    "  \"Saves a CNDF dataframe of the ConvNav instance `cn` to persistent storage at `path` with `filename` gzip compresseed\"\n",
    "  if not with_modules: df = cn._cndf.iloc[:,:-1]\n",
    "  with gzip.open(path+filename, \"wb\") as f:\n",
    "    pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In native format, CNDF dataframes include the module objetcs in a 'lyr_obj' column and so can be quite large, 100-200mb for a complex model such as a densenet or xresnet. Thus, by default, module objects are removed from the dataframe before saving. To save the model objects as well, check you have enough space in the download location and set `with_modules` to True. Dataframes are gzip compressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_cndf(filename, path=''):\n",
    "  \"Loads a CNDF dataframe from persistent storage at `path`+`filename` and unzips it\"\n",
    "  with gzip.open(path+filename, \"rb\") as f:\n",
    "    return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#save example ConvNav Learner, Learner.summary() and and df to use in testing and exmaples\n",
    "# with gzip.open(\"test_learner_resnet18\", \"wb\") as f:\n",
    "#     pickle.dump(learn, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with gzip.open(\"test_summary_resnet18\", \"wb\") as f:\n",
    "#     pickle.dump(learn.summary(), f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# df_test = cn_test._cndf.iloc[:,:-1]\n",
    "# with gzip.open(\"test_df_resnet18\", \"wb\") as f:\n",
    "#     pickle.dump(df_test, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_df = None\n",
    "test_learner = None\n",
    "test_summary = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#download the example Convnav object and df\n",
    "with gzip.open(\"test_df_resnet18\", \"rb\") as f:\n",
    "    test_df = pickle.load(f)\n",
    "\n",
    "with gzip.open(\"test_summary_resnet18\", \"rb\") as f:\n",
    "    test_summary = pickle.load(f)\n",
    "\n",
    "with gzip.open(\"test_learner_resnet18\", \"rb\") as f:\n",
    "    test_learner = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
